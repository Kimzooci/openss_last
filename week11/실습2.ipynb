{"cells":[{"cell_type":"markdown","metadata":{"id":"tEqHeHmEL3IF"},"source":["# 데이터 전처리 실습\n","## Orange Telecom Churn Data 실습\n","### 1. 패키지 불러오기"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aq_dJA91L_qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcRqc84mL3IG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import KNNImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"markdown","metadata":{"id":"OZNgpE-jL3IH"},"source":["### 2. 데이터 분석\n","1. 데이터의 크기 출력\n","2. 데이터의 특징 출력\n","3. 데이터의 정보 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PP2AxlkWL3IH"},"outputs":[],"source":["# load dataset\n","data_path = '/content/drive/MyDrive/Colab Notebooks/opensource/week11/Orange_Telecom_Churn_Data.csv'\n","data = pd.read_csv(data_path)\n","# print the shape of the dataset\n","print(\"Shape of the dataset: \", data.shape)\n","# print the columns of the dataset\n","print(\"Columns of the dataset: \", data.columns)\n","# print the info of the dataset\n","print(\"Info of the dataset: \", data.info())\n"]},{"cell_type":"markdown","metadata":{"id":"8DTouJHkL3IH"},"source":["### 3. 데이터 전처리\n","1. 학습데이터와 테스트 데이터 나누기\n","2. 데이터 중복 제거\n","3. 필요없는 특징 제거"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65peDRSrL3IH"},"outputs":[],"source":["# split the dataset into features and target\n","X = data.drop(['churned'], axis=1)\n","y = data['churned']\n","\n","X = X.drop(['state', 'area_code', 'phone_number'], axis=1)\n","\n","# split the dataset into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# print the shape of the training and testing datasets\n","print(\"Shape of the training dataset: \", X_train.shape)\n","print(\"Shape of the testing dataset: \", X_test.shape)\n","\n","# delete duplicates in the training dataset\n","X_train = X_train.drop_duplicates()\n","y_train = y_train.loc[X_train.index]\n","\n","print(\"Shape of the training dataset after deleting duplicates: \", X_train.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"7q8luERYL3II"},"source":["### 3. 데이터 전처리\n","3. 누락 데이터 대체\n","\n","(1) 평균값, 최빈값으로 대체\n","\n","연속값이 있는 특징 -> 평균값\n","\n","범주형 데이터가 있는 특징 -> 최빈값"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gLoo97zL3II"},"outputs":[],"source":["# for numerical columns, fill missing values with the mean of the column\n","# for categorical columns, fill missing values with the mode of the column\n","\n","# get the numerical columns\n","num_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n","# get the categorical columns\n","cat_columns = X_train.select_dtypes(include=['object']).columns\n","\n","X_mean_imputed = X_train.copy()\n","y_mean_imputed = y_train.copy()\n","\n","X_test_mean_imputed = X_test.copy()\n","y_test_mean_imputed = y_test.copy()\n","\n","# fill missing values\n","for col in num_columns:\n","    X_mean_imputed[col].fillna(X_mean_imputed[col].mean(), inplace=True)\n","    X_test_mean_imputed[col].fillna(X_test_mean_imputed[col].mean(), inplace=True)\n","\n","for col in cat_columns:\n","    X_mean_imputed[col].fillna(X_mean_imputed[col].mode()[0], inplace=True)\n","    X_test_mean_imputed[col].fillna(X_test_mean_imputed[col].mode()[0], inplace=True)\n","\n","\n","print(\"Missing values filled\")\n","# print the number of missing values in the training dataset\n","print(\"Number of missing values in the training dataset: \", X_mean_imputed.isnull().sum().sum())\n","# print the number of missing values in the testing dataset\n","print(\"Number of missing values in the testing dataset: \", X_test_mean_imputed.isnull().sum().sum())\n"]},{"cell_type":"markdown","metadata":{"id":"59QiHYsGL3II"},"source":["(2) k-최근접 이웃을 활용한 대체"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCSkI9eaL3IJ"},"outputs":[],"source":["# fill missing values using k-NN\n","X_knn_imputed = X_train.copy()\n","y_knn_imputed = y_train.copy()\n","\n","X_test_knn_imputed = X_test.copy()\n","y_test_knn_imputed = y_test.copy()\n","\n","knn_imputer = KNNImputer(n_neighbors=5)\n","\n","X_knn_imputed[num_columns] = knn_imputer.fit_transform(X_knn_imputed[num_columns])\n","X_test_knn_imputed[num_columns] = knn_imputer.transform(X_test_knn_imputed[num_columns])\n","\n","for col in cat_columns:\n","    X_knn_imputed[col].fillna(X_knn_imputed[col].mode()[0], inplace=True)\n","    X_test_knn_imputed[col].fillna(X_test_knn_imputed[col].mode()[0], inplace=True)\n","\n","\n","print(\"Missing values filled using k-NN\")\n","print(\"Number of missing values in the training dataset: \", X_knn_imputed.isnull().sum().sum())\n","print(\"Number of missing values in the testing dataset: \", X_test_knn_imputed.isnull().sum().sum())\n"]},{"cell_type":"markdown","metadata":{"id":"MRmFJk-mL3IJ"},"source":["### 3. 데이터 전처리\n","4. 데이터 형식 문제 제거 (레이블 인코딩)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1j4u5zWL3IJ"},"outputs":[],"source":["le = LabelEncoder()\n","cat_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n","# fit the LabelEncoder on both training and testing data\n","# transform the categorical columns in X_knn_imputed and X_test_knn_imputed, X_mean_imputed and X_test_mean_imputed\n","for col in cat_columns:\n","    le.fit(X_train[col])\n","    X_knn_imputed[col] = le.transform(X_knn_imputed[col])\n","    X_test_knn_imputed[col] = le.transform(X_test_knn_imputed[col])\n","\n","for col in cat_columns:\n","    le.fit(X_train[col])\n","    X_mean_imputed[col] = le.transform(X_mean_imputed[col])\n","    X_test_mean_imputed[col] = le.transform(X_test_mean_imputed[col])\n","\n","print(\"Label encoding completed\")\n"]},{"cell_type":"markdown","metadata":{"id":"qwdZ1-JjL3IJ"},"source":["5. 이상치 탐지 및 제거"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Qdc1JzxL3IJ"},"outputs":[],"source":["# find ouliers in the training dataset\n","# calculate the z-scores of the numerical columns\n","# make function\n","def remove_outliers(X, y):\n","    z_scores = (X[num_columns] - X[num_columns].mean()) / X[num_columns].std()\n","    outliers = z_scores[(z_scores > 3).any(axis=1)].index\n","    X_no_outliers = X.drop(outliers)\n","    y_no_outliers = y.loc[X_no_outliers.index]\n","    return X_no_outliers, y_no_outliers\n","\n","print(\"Shape of the training dataset before removing outliers (KNN): \", X_knn_imputed.shape)\n","print(\"Shape of the testing dataset before removing outliers (KNN): \", X_test_knn_imputed.shape)\n","print(\"Shape of the training dataset before removing outliers (MEAN): \", X_mean_imputed.shape)\n","print(\"Shape of the testing dataset before removing outliers (MEAN): \", X_test_mean_imputed.shape)\n","\n","X_knn_no_outliers, y_knn_no_outliers = remove_outliers(X_knn_imputed, y_knn_imputed)\n","X_mean_no_outliers, y_mean_no_outliers = remove_outliers(X_mean_imputed, y_mean_imputed)\n","\n","X_test_knn_no_outliers, y_test_knn_no_outliers = remove_outliers(X_test_knn_imputed, y_test_knn_imputed)\n","X_test_mean_no_outliers, y_test_mean_no_outliers = remove_outliers(X_test_mean_imputed, y_test_mean_imputed)\n","\n","print(\"Shape of the training dataset after removing outliers (KNN): \", X_knn_no_outliers.shape)\n","print(\"Shape of the testing dataset after removing outliers (KNN): \", X_test_knn_no_outliers.shape)\n","print(\"Shape of the training dataset after removing outliers (MEAN): \", X_mean_no_outliers.shape)\n","print(\"Shape of the testing dataset after removing outliers (MEAN): \", X_test_mean_no_outliers.shape)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J7Ps9CylL3IJ"},"source":["### 데이터 변환\n","1. 데이터 표준화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-haJ86SL3IJ"},"outputs":[],"source":["# standardize the numerical columns\n","scaler = StandardScaler()\n","X_knn_standardized = X_knn_no_outliers.copy()\n","X_test_knn_standardized = X_test_knn_no_outliers.copy()\n","X_mean_standardized = X_mean_no_outliers.copy()\n","X_test_mean_standardized = X_test_mean_no_outliers.copy()\n","\n","X_knn_standardized[num_columns] = scaler.fit_transform(X_knn_no_outliers[num_columns])\n","X_test_knn_standardized[num_columns] = scaler.transform(X_test_knn_no_outliers[num_columns])\n","\n","X_mean_standardized[num_columns] = scaler.fit_transform(X_mean_no_outliers[num_columns])\n","X_test_mean_standardized[num_columns] = scaler.transform(X_test_mean_no_outliers[num_columns])\n","\n","print(\"Standardization completed\")"]},{"cell_type":"markdown","metadata":{"id":"NtSe5jBRL3IJ"},"source":["2. 데이터 정규화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mERuMbVzL3IJ"},"outputs":[],"source":["# normalize the numerical columns\n","scaler = MinMaxScaler()\n","X_knn_normalized = X_knn_standardized.copy()\n","X_test_knn_normalized = X_test_knn_standardized.copy()\n","X_mean_normalized = X_mean_standardized.copy()\n","X_test_mean_normalized = X_test_mean_standardized.copy()\n","\n","X_knn_normalized[num_columns] = scaler.fit_transform(X_knn_standardized[num_columns])\n","X_test_knn_normalized[num_columns] = scaler.transform(X_test_knn_standardized[num_columns])\n","\n","X_mean_normalized[num_columns] = scaler.fit_transform(X_mean_standardized[num_columns])\n","X_test_mean_normalized[num_columns] = scaler.transform(X_test_mean_standardized[num_columns])\n","\n","print(\"Normalization completed\")"]},{"cell_type":"markdown","metadata":{"id":"nsVSUm4XL3IK"},"source":["### 성능 평가\n","kNN을 사용하여 데이터간의 성능을 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0R3P1THL3IK"},"outputs":[],"source":["# check accuracy using kNN classifier\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","knn = KNeighborsClassifier(n_neighbors=5)\n","knn.fit(X_knn_normalized, y_knn_no_outliers)\n","y_pred_knn = knn.predict(X_test_knn_normalized)\n","accuracy_knn_normalized = accuracy_score(y_test_knn_no_outliers, y_pred_knn)\n","\n","knn.fit(X_knn_standardized, y_knn_no_outliers)\n","y_pred_knn = knn.predict(X_test_knn_standardized)\n","accuracy_knn_standardized = accuracy_score(y_test_knn_no_outliers, y_pred_knn)\n","\n","knn.fit(X_knn_no_outliers, y_knn_no_outliers)\n","y_pred_knn = knn.predict(X_test_knn_no_outliers)\n","accuracy_knn_no_outliers = accuracy_score(y_test_knn_no_outliers, y_pred_knn)\n","\n","knn.fit(X_knn_imputed, y_knn_imputed)\n","y_pred_knn = knn.predict(X_test_knn_imputed)\n","accuracy_knn_imputed = accuracy_score(y_test_knn_imputed, y_pred_knn)\n","\n","# make a DataFrame to store the accuracy scores\n","accuracy_scores_knn = pd.DataFrame({\n","    'Method': ['No outliers', 'With outliers', 'Standardized', 'Normalized'],\n","    'Accuracy': [accuracy_knn_no_outliers, accuracy_knn_imputed, accuracy_knn_standardized, accuracy_knn_normalized]\n","})\n","\n","print(accuracy_scores_knn)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thuySIpZL3IK"},"outputs":[],"source":["# check same but using mean imputed data\n","knn.fit(X_mean_normalized, y_mean_no_outliers)\n","y_pred_knn = knn.predict(X_test_mean_normalized)\n","accuracy_knn_normalized = accuracy_score(y_test_mean_no_outliers, y_pred_knn)\n","\n","knn.fit(X_mean_standardized, y_mean_no_outliers)\n","y_pred_knn = knn.predict(X_test_mean_standardized)\n","accuracy_knn_standardized = accuracy_score(y_test_mean_no_outliers, y_pred_knn)\n","\n","knn.fit(X_mean_no_outliers, y_mean_no_outliers)\n","y_pred_knn = knn.predict(X_test_mean_no_outliers)\n","accuracy_knn_no_outliers = accuracy_score(y_test_mean_no_outliers, y_pred_knn)\n","\n","knn.fit(X_mean_imputed, y_mean_imputed)\n","y_pred_knn = knn.predict(X_test_mean_imputed)\n","accuracy_knn_imputed = accuracy_score(y_test_mean_imputed, y_pred_knn)\n","\n","# make a DataFrame to store the accuracy scores\n","accuracy_scores_mean = pd.DataFrame({\n","    'Method': ['No outliers', 'With outliers', 'Standardized', 'Normalized'],\n","    'Accuracy': [accuracy_knn_no_outliers, accuracy_knn_imputed, accuracy_knn_standardized, accuracy_knn_normalized]\n","})\n","print(accuracy_scores_mean)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNy5p4VhL3IK"},"outputs":[],"source":["# aggregate the accuracy scores for both mean imputed and k-NN imputed data\n","#  big 2 columns (knn and mean)\n","accuracy_scores = pd.concat([accuracy_scores_knn, accuracy_scores_mean], keys=['knn', 'mean'])\n","print(accuracy_scores)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}